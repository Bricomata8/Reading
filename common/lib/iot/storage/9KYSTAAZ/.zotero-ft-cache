2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)

Joint Service Pricing and Cooperative Relay Communication for Federated Learning

Shaohan Feng1, Dusit Niyato1, Ping Wang2, Dong In Kim3, and Ying-Chang Liang4 1 School of Computer Engineering, Nanyang Technological University, Singapore 2 Department of Electrical Engineering and Computer Science, York University, Canada 3 School of Information and Communication Engineering, Sungkyunkwan University, Korea
4 CINC, University of Electronic Science and Technology of China, China

Abstractâ€”For the sake of protecting data privacy and due to the rapid development of mobile devices, e.g., powerful central processing unit (CPU) and nascent neural processing unit (NPU), collaborative machine learning on mobile devices, e.g., federated learning, has been envisioned as a new AI approach with broad application prospects. However, the learning process of the existing federated learning platforms rely on the direct communication between the model owner, e.g., central cloud or edge server, and the mobile devices for transferring the model update. Such a direct communication may be energy inefï¬cient or even unavailable in mobile environments. In this paper, we consider adopting the relay network to construct a cooperative communication platform for supporting model update transfer and trading. In the system, the mobile devices generate model updates based on their training data. The model updates are then forwarded to the model owner through the cooperative relay network. The model owner enjoys the learning service provided by the mobile devices. In return, the mobile devices charge the model owner certain prices. Due to the coupled interference of wireless transmission among the mobile devices that use the same relay node, the rational mobile devices have to choose their relay nodes as well as deciding on their transmission powers. Thus, we formulate a Stackelberg game model to investigate the interaction among the mobile devices and that between the mobile devices and the model owner. The Stackelberg equilibrium is investigated by capitalizing on the exterior point method. Moreover, we provide a series of insightful analytical and numerical results on the equilibrium of the Stackelberg game.
Index Termsâ€”Federated learning, Security privacy, Energy efï¬cient, Network optimization, Stackelberg game.
I. INTRODUCTION
Due to the explosive growth of smart IoT devices at the edge of the Internet, massive data collection through embedded sensors on mobile devices, e.g., crowdsensing, for machine learning has found a number of applications and gained tremendous popularity rapidly [1]. However, the existing machine learning approaches rely on centralized storage of the training data. Consequently, they usually face a series of data security and privacy issues, e.g., data abuse and information leakage. A recent report from Ponemon Institute suggests an average cost of over $200 for per record of data breach [2]. Such a high economic loss has hindered the adoption of data sharing among the different entities, and the machine learning that requiring centralized data storage is facing great challenges.
To overcome the limitations of traditional machine learning in the protection of data privacy, a novel paradigm has been

proposed. In [3], the federated learning system was introduced to address the issue of data privacy. Therein, the mobile devices perform computation of model training locally on their training data according to the model released by the model owner. Such design enables mobile device to collaboratively learn a shared prediction model while keeping all the training data on the device [4]. However, the independent and rational mobile devices need incentive to participate in federated learning. In practice, asking the mobile devices to work as sacriï¬cial volunteers is not an economically viable and sustainable option. Moreover, in the federated learning paradigm, the direct communication between model owner and mobile devices is still required for transferring model updates, i,e., Fig. 1(a). In many scenarios, the direct communication may be unavailable because of limited transmission range and energy inefï¬ciency because of high transmission power.
To address the incentive issues of the mobile devices, we adopt the service pricing scheme to motivate the mobile devices to participate in federated learning. Under the service pricing scheme, the machine learning is provided by the mobile devices as a service to the model owner. Then, the learning service, i.e., model update generation and trading as well as data collection, is performed in a decentralized manner. Additionally, to overcome the energy inefï¬ciency in the model update transfer for the mobile devices, we resort to relay networking to ensure that the model updates are transferred in a cooperative manner. The mobile devices cooperatively form a relay network by providing relay service to each other and directly or indirectly connect to the access point of the model owner for model update transfer, e.g., Fig. 1(b). Note here that the mobile device that acts as the relay node will use the average operator to combine its own model update with its received model updates. Then, the ï¬le size of the model update is not affected, and hence providing relay service does not signiï¬cantly affect the energy consumption of the mobile devices.
In this paper, we propose a novel framework of cooperative federated learning system. Our designed federated learning system involves two parties, i.e., the massive-scale mobile devices working as learning service providers, and the model owner handling the learning task dispatching (model releasing) and model updates collection. The mobile devices price their learning service by deciding on the price of one unit of their training data. In return, the model owner determines the size

978-1-7281-2980-8/19/$31.00 Â©2019 IEEE

815

DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00148

Figure 1: (a) Original communication scenario for federated learning; (b) Our designed communication scenario for federated learning.
of training data for each mobile device. As such, under the service pricing scheme, the mobile devices optimize the prices of their data to motivate the model owner to determine a larger size of training data and hence maximize their proï¬ts. However, under the cooperative relay network design, the larger size of training data implies the lower probability of enjoying the relay service. As a result, the learning service pricing and cooperative relaying should be considered jointly. By using the pricing-based data rent and a self-organized relay network design shown in Fig 1(b) for federated learning, the following key properties are guaranteed in our system:
â€¢ The model update throughput of the model owner scales well such that the massive model update volume from the mobile devices is handled smoothly.
â€¢ The rational and self-interested mobile devices noncooperatively decide on their own price of one unit of training data for individual proï¬t optimization and cooperatively transfer their model updates.
â€¢ Signiï¬cantly reduces the congestion in the communication for both the model owner and the mobile devices.
The rest of the paper is organized as follows. Section II describes the system model. Section III presents the formulation of a Stackelberg game. Section IV analyzes the equilibrium of the proposed Stackelberg game. Section V presents the numerical performance evaluation. Section VI concludes the paper.
II. SYSTEM DESCRIPTION
We consider a cooperative federated learning system as shown in Fig. 1(b). Speciï¬cally, a model owner employs a set of mobile devices, e.g., mobile phones, to train a high-quality centralized model [5]. The set of mobile devices is denoted by N 0, e.g., mobile devices 1, 2, and 3 in Fig. 1(b). Each mobile device i âˆˆ N 0 uses a part of its data and performs computation on its data locally to generate the model update for training the model of the model owner. The model owner negotiates with the mobile devices about the size of their training data, i.e., sdi . In return, each mobile device i âˆˆ N 0 will receive

Table I: Notations

Symbol i, ND
N0 N , |N |
Pij Tis, Tia
hij , dij
qi, sdi
cpi , cti ca Id ri

Description Node i and the access point of the model owner.
The set of mobile devices. N = N 0 âˆª {ND} = 1, 2, . . . , N 0 , ND is a sorted set and its cardinality. The transmission power used by mobile device i to transfer the model update to mobile device j. The time used by mobile device i for processing the model update and average operator, respectively. The channel gain of the transmission between mobile devices i and j, and the distance between mobile devices i and j. The price of one unit of training data for mobile device i and the size of the data set used by mobile device i for generated the model update. The costs that mobile device i uses one unit of energy for processing one unit of data and transferring, respectively. The fee that each mobile device i âˆˆ N charged by its rely node for the relay service.
The size of the model update. The transmission rate of mobile device i.

the revenue qisdi from the model owner, where qi is the price for one unit of mobile device iâ€™s training data. Intuitively, the learning accuracy of the model depends on the total size of all the mobile devicesâ€™ training data. Speciï¬cally, the learning accuracy of the model becomes higher as the total size of all the mobile devicesâ€™ training data increases. In this case, we incorporate the results in [6] to describe the relationship between the learning accuracy of the model and the total size of all the mobile devicesâ€™ training data. As a result, the utility of the model owner is deï¬ned as follows:

U sd, q = f sd âˆ’

qisdi ,

(1)

iâˆˆN 0

where f (Â·) is the function describing the relationship between the learning accuracy of the model and the total size of all the mobile devicesâ€™ training data [6]. Note here that f (Â·) is an increasing concave function implying that the learning accuracy of the model keeps increasing as the size of training data increases while the marginal increasing speed of the learning accuracy of the model decreases [6].
The mobile devices can cooperate with each other for transferring their model updates to the access point of the model owner. Let Pij denote the transmission power used by mobile device i for transferring its model update to mobile device j, where we deï¬ne the transmission power matrix P = [pij]i,jâˆˆN . Iij is the element of the indicator matrix I, i.e., I = [Iij]i,jâˆˆN , and deï¬ned as follows:

Iij =

1, Pij > 0 0, Otherwise

, âˆ€i, j âˆˆ N .

(2)

To provide the learning service, mobile device i has the cost of cpi sdi due to the energy consumption incurred from the computation. Moreover, each mobile device i âˆˆ N 0 has another
cost incurred by the wireless transmission of its model update. Let cti be the cost that mobile device i uses one unit of power for wireless transmission, the instantaneous cost for mobile

816

device i incurred by the transmission is cti Pij. Under the
jâˆˆN
assumption that the sizes of the model updates transferred by

the mobile devices are the same, the energy consumption from

the wireless transmission depends on the transmission rate of

each mobile device, i.e., ri. We denote the size of the model update by Id. The time for transferring the model update is

accordingly

Id ri

,

and

hence

the

energy

consumption

of

mobile

device

i

incurred

by

the

wireless

transmission

is

cti

Id ri

jâˆˆN

Pij .

Furthermore, with the relay service among the mobile devices,

each mobile device i âˆˆ N 0 will have a revenue of ca

Iji

jâˆˆN 0
due to its provided relay service while a cost of ca (1 âˆ’ IiND ) incurred by the use of the relay service. ca (1 âˆ’ IiND ) comes

from the fact that mobile device i uses the relay service and

hence pay the fee ca if it does not directly transfer the model

update to the model owner, i.e., IiND = 0. Finally, with the revenue of providing the learning service to the model owner, i.e., qisdi , the corresponding proï¬t of mobile device i is

Î i

P, qi, sdi

=

qi sdi

âˆ’

cti

Id ri

jâˆˆN

Pij

âˆ’

cpi sdi

(3)

+ ca

Iji âˆ’ ca 1 âˆ’ IiND + vi.

jâˆˆN 0

To form the wireless relay networks among the mobile

devices and hence achieve the energy efï¬cient communication

for the model update transfer, we have two sets of constraints.

The ï¬rst set of the constraints is for the routing. The second

set of the constraints is for the model update arrival time at

the relay point.

For the routing, we ï¬rst have the constraint to ensure that

every mobile device can connect to and transfer its model

update to only one of other mobile devices or directly to the

access point of the model owner. The constraint is expressed

as follows:

Iij = 1 and Iii = 0, âˆ€i âˆˆ N 0.

(4)

jâˆˆN

Secondly, we have the constraint that at least one mobile

device connects to the access point of the model owner and

acts as one of the last-hop nodes. Otherwise, none of the

mobile devices can transfer the model update to the model

owner. The corresponding constraint is expressed as follows:

IiND â‰¥ 1.

(5)

iâˆˆN 0

We then have the constraint that the model update of each mobile device can ï¬nally and afï¬rmatively arrive at the model owner. That is, each mobile device can transfer its model update to the model owner after a limited number of mobile devices as its relay nodes, i.e.,

I|N 0|âˆ’1 = ID,

(6)

where

â¡ 0 Â· Â· Â· 0 â¤ â†1

ID

= â¢â¢â¢â¢â¢â£

... 0

... Â·Â·Â·

... 0

â¥â¥â¥â¥â¥â¦

... â†

N0

.

(7)

1 Â· Â· Â· 1 â†ND

Regarding the constraint for the model update arrival time

on the relay node, we have the constraint in (8). This constraint

is to ensure that the model update of mobile device i will

arrive at mobile device j before mobile device j ï¬nishes the

computing of its model update if mobile device i wants to

transfer its model update by choosing mobile device j as its

relay node. The time used by mobile device i for providing

the learning service can be divided into three periods. The ï¬rst

time period, denoted by Tis, is for performing the computation

on the training data according to the model. The model update

is generated at the end of this time period. Suppose that rip

is the processing rate of mobile device i, Tis is accordingly

deï¬ned device

iastoTisp=rovrsiidipde[7r]e.laTyhesesrevciocned

time period is for mobile to other mobile devices.

For each received model update from another mobile device,

mobile device i needs to spend the time of Tia for combining the received model update with its own model update by using

the average operator. The length of the second time period

is therefore linearly related to the number of model updates

received by mobile device i, i.e., the number of mobile devices

that use mobile device iâ€™s relay service Iji, and expressed

jâˆˆN

as Tia Iji. The last time period is for mobile device i to

jâˆˆN

transfer

its

model

update

and

expressed

as

Id ri

,

where

ri

is

the

transmission rate of mobile device i deï¬ned in (9). To ensure

that mobile device i can successfully use the relay service

from other mobile devices, the sum of three time periods at

mobile device i must be shorter than the ï¬rst time period of

its relay node, i.e.,

Tis + Tia

Iji +

jâˆˆN 0

Id ri

â‰¤

Iij Tjs, âˆ€i âˆˆ N 0.

jâˆˆN 0

(8)

We assume that the mobile devices using the same relay

node share the channel and hence generate mutual interference.

Let hij denote the channel gain from mobile device i to mobile device j, dij be the distance between mobile devices i and j, and Î± â‰¥ 2 be the path loss coefï¬cient of wireless

communication. Then, we deï¬ne a matrix H = [Hij]i,jâˆˆN ,

the

element

of

which,

i.e.,

Hij ,

is

. hij
(dij )Î±

Accordingly,

the

propagation model for data transmission of mobile device i,

i.e., the transmission rate of mobile device i, ri is given by

â› ri = wilog2 âœâœâ1 + (HI (:, i))

jâˆˆN

hij
(dij )Î±

Pij

(PI (:, i)) âˆ’
jâˆˆN

hij
(dij )Î±

Pij

+

Ïƒ2

â âŸâŸâ 

= wilog2

1+

(H (i, :)) (P (i, :))

(HI (:, i)) (PI (:, i)) âˆ’ (H (i, :)) (P (i, :)) + Ïƒ2

,

(9)

where Ïƒ2 is the noise, wi is the bandwidth of mobile device i, PI = PI , and HI = HI . Note here that we use H (i, :) and H (:, i) to represent the i-th row vector and i-th column

vector of H, respectively, and the usage of this notation is

deï¬ned similarly in the rest of this paper.

817

III. STACKELBERG GAME FORMULATION
In this section, we model the interaction between the mobile devices and the model owner as a Stackelberg game. In the Stackelberg game, the model owner is the buyer as it uses the learning service provided by the mobile devices. Then, the mobile devices that are the service providers act as the sellers. The sellers typically make their decisions before the buyers. Following this case, the model owner inherently acts as the single follower in the lower level of the Stackelberg game while the mobile devices are the corresponding leaders. In the lower level of the game, i.e., the lower-level subgame, the model owner determines the size of training data for the mobile devices. In the upper level, i.e., the upper-level subgame, the mobile devices decide on the price for one unit of their training data. Moreover, since the mobile devices cooperatively send their model update to the model owner, each mobile device also needs to independently decide on its relay node as well as its transmission power. As a result, the Stackelberg game can be formally deï¬ned as follows:
1) Lower-level subgame: Given the ï¬xed vector of the prices of one unit of training data q = q1, . . . , q|N 0| , the lower-level subgame is deï¬ned by the a three-tuple GL = sd, Sd, U , where
â€¢ sd = sd1 , . . . , sd|N 0| is the vector of the sizes of training data;
â€¢ Sd = sd1 , . . . , sd|N 0| sdi âˆˆ 0, sdi ,u , i âˆˆ N 0
âŠ‚ R|N 0| is the domain of deï¬nition for sd and an M-polyhedron, where sdi ,u is the upper bound of sdi ; â€¢ U = U sd, q is the utility function of the model owner deï¬ned in (1);
2) Upper-level subgame: After the model ownerâ€™s demand of data size sd is determined in the lower-level subgame, the mobile devices form a upper-level subgame deï¬ned by a six-tuple GU = N 0, P, P, q, Q, Î  , where â€¢ N 0 is the set of the mobile devices; â€¢ P = [Pij]i,jâˆˆN is the matrix of the power for wireless transmission; â€¢ P = [Pij ]i,jâˆˆN Pij âˆˆ 0, Piuj , i, j âˆˆ N âŠ‚ R|N |Ã—|N | is the domain of deï¬nition for P, where Piuj is the upper bound of Pij; â€¢ q = q1, . . . , q|N 0| is the vector of prices for one unit of training data. â€¢ Q = q1, . . . , q|N 0| qi âˆˆ [0, qiu] , i âˆˆ N 0 âŠ‚ R|N 0| is the domain of deï¬nition for q and an Mpolyhedron, where qiu is the upper bound of qi; â€¢ Î  = Î 1, . . . , Î |N 0| is the vector of the proï¬ts for the mobile devices, where Î i = Î i P, qi, sdi is the proï¬t of mobile device i deï¬ned in (3).
Based on the game formulation, we consider a Stackelberg equilibrium to be the solution for the model owner and the mobile devices.

IV. EQUILIBRIUM ANALYSIS
By following the backward induction, we ï¬rstly use the ï¬rst-order optimality condition to obtain the optimal solution to the lower-level subgame GL. The existence of the optimal solution to the lower-level subgame GL is proven to exist by showing the concavity of its utility function. This optimal solution is further proven to be unique by showing the negative deï¬niteness of the Hessian matrix of the utility function of the lower-level subgame GL. Then, we substitute the NE of the lower-level subgame GL into the upper-level subgame GU and investigate the solution to the upper-level subgame GU by capitalizing on the exterior point method.

A. Solution to Lower-level Subgame

To ï¬nd an optimal solution for the lower-level subgame GL,

we need to take the ï¬rst derivative of the utility function of

the model owner given in (1) with respect to sdi as follows:

â¡

â¤

âˆ‚ âˆ‚sdi U

sd, q

=

âˆ‚ âˆ‚sdi

â£f

sd

âˆ’

qisdi â¦

iâˆˆN 0

(10)

=

âˆ’

qi

+

âˆ‚ âˆ‚sdi

f

sd

, âˆ€i âˆˆ N 0,

where f sd =

fi sdi . Without loss of generality

iâˆˆN 0

and for the trackable analysis, we adopt Weibull model as

suggested in [6], i.e., fi sdi

râˆ‚eâˆ‚ssdipUonssedo, qf

= 0, âˆ€i âˆˆ N the model owner,

= ai âˆ’ bi exp 0, we have sdi âˆ—, as follows:

âˆ’cisdi . i.e., the

Let best

âˆ’

qi

+

âˆ‚ âˆ‚sdi f

sd

=

âˆ’qi

+

âˆ‚ âˆ‚sdi

ai âˆ’ bi exp

âˆ’ci sdi

(11)

= âˆ’ qi + cibi exp âˆ’cisdi

=

0

â‡”

sdi âˆ—

=

1 ci

ln

ci bi qi

Due to the strict concavity of fi (Â·) and the linearity of âˆ’qisdi with respect to sdi , U sd, q is therefore concave with respect to sdi and its concavity indicates the existence of the solution to the lower-level subgame GL. Moreover, with negative elements
on the primary diagonal and zero elements on the off-diagonal, the Hessian matrix of U sd, q is negative deï¬nite, and hence

the solution to the lower-level subgame GL is unique.

B. Solutions to Upper-level Subgame

After obtaining the optimal demand of the data size for the model owner, we investigate the upper-level subgame GU for the mobile devices. At the Nash Equilibrium (NE), no player can increase its proï¬t by choosing a different strategy provided that the other playersâ€™ strategy is unchanged [8]. We ï¬rstly substitute the optimal demand of the data size for the model owner given in (11) into the proï¬t functions of the mobile devices given in (3) and have the new proï¬t functions for the mobile devices as follows:

Î i (P, qi) =Î i

P, qi, sdi âˆ—

=

qi

1 ci

ln

ci bi qi

âˆ’

cti

Id ri

Pij
jâˆˆN

âˆ’

cpi

1 ci

ln

ci bi qi

+ ca

Iji âˆ’ ca

jâˆˆN 0

1 âˆ’ IiND

+ vi

(12)

with the constraints (4)-(8).

818



   

0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH 0RELOHGHYLFH $FFHVVSRLQW







Figure 2: The wireless relay network for cooperative model update transfer.

V. PERFORMANCE EVALUATION

In this section, we present numerical studies to evaluate

the performance of the cooperative federated learning

system. For the ease of illustration, we consider 9 mobile

devices, i.e, N 0 = 9, working as the learning entities.

The bandwidth and channel gain are respectively hij = 1 and wi = 100, âˆ€i, j âˆˆ N 0, and the noise Ïƒ2 is 1. The size of the model update is assumed to be Id = 0.001. The

distances among the mobile devices as well as that between

the mobile devices and the access point of the model owner,

i.e., d = [dij]i,jâˆˆN , follows a uniform distribution under the plane of [0, 150] Ã— [0, 150]. The vector of the costs of

consuming one unit of power for wireless communication

is ct = [cti]iâˆˆN 0 = [150] processing one unit of data

. The is cp

vector of the costs of = [cpi ]iâˆˆN 0 = [0.01].

We set the fee of relay service to be ca = 0.01. The

vector of processing rate is rp = [rip]iâˆˆN 0 = [0.01] .

The vector of the time of using average operator for

the mobile devices is Ta = [Tia]iâˆˆN 0 = [0.01]. The coefï¬cient of fi (Â·) deï¬ned in (1) is c = [cij]i,jâˆˆN 0 = [13.28, 9.17, 14.31, 11.21, 9.12, 13.61, 13.27, 9.63, 14.32]

and a = [aij ]i,jâˆˆN 0 = b = [bij ]i,jâˆˆN 0 = [9.78, 9.15, 11.35, 11.17, 12.7, 9.15, 12.38, 13.5, 10.59]. vi is equal to 10 for all i âˆˆ N . Piuj is 10 for all i, j âˆˆ N .

A. Numerical Result

For the convenience to observe the routing result for the cooperative model update transfer, We present it in Fig. 2 and Table II. As shown in Fig. 2, the mobile devices selforganize the wireless rely network for cooperative model update transfer. For example, mobile device 3 uses mobile device 7 as the relay node for transferring the model update. This can signiï¬cantly reduce the energy consumption of wireless communication for mobile device 3. Moreover, both mobile devices 4 and 5 choose the same mobile device, i.e, mobile

7KHSURILWVRIWKHPRELOHGHYLFHV

Table II: The routing result for cooperative model update transfer.

Mobile device No. 1 2 3 4 5 6 7 8 9

Routing
1 â†’ ND. 2 â†’ 5 â†’ 6 â†’ 1 â†’ ND. 3 â†’ 7 â†’ 8 â†’ ND. 4 â†’ 6 â†’ 1 â†’ ND. 5 â†’ 6 â†’ 1 â†’ ND. 6 â†’ 1 â†’ ND. 7 â†’ 8 â†’ ND. 8 â†’ ND. 9 â†’ 2 â†’ 5 â†’ 6 â†’ 1 â†’ ND.

 
    
 0RELOHGHYLFH1R
Figure 3: The proï¬ts of the mobile devices.

device 6, as their relay node. This will incur the mutual interference between mobile devices 4 and 5 and hence result in energy inefï¬cient communication. However, compared with choosing other mobile devices as the relay node or directly transferring the model update to the cental cloud, it is more energy efï¬cient to choose mobile device 6 as the relay node for mobile devices 4 and 5.
We next evaluate the proï¬ts for the mobile devices. As shown in Fig. 3, we observe that the proï¬t of mobile device 4 is the highest one among the mobile device. The reason is that the model update from mobile device 4 has a signiï¬cant improvement on the model of the owner. This means that the model update from mobile device 4 contains much more valuable information than the other mobile devices. In contrast, although the model update from mobile device 6 is the combination of the model updates from the model updates of mobile devices 4 and 5, its proï¬t is much less than that of mobile device 4. This is due to the data quality of mobile device 6 and the preference of the model owner.
We then investigate the sizes of the training data for the model owner. As shown in Fig. 4, the size of the training data from mobile device 1 is the largest among the mobile devices. This is due to the shortest distance between the access point and mobile device 1. Moreover, due to the longest data

819

7KHVL]HRIGDWD






  0RELOHGHYLFH1R
Figure 4: The size of training data for each mobile device.
processing time, mobile device 1 can make more proï¬t by acting as the relay node for other mobile devices. Comparing with mobile device 1, the size of data of mobile device 4 is much less. The reason is that mobile device 4 needs to use the other mobile devices as its relay node, and hence the update of mobile device 4 needs to be transferred before its relay node ï¬nishes the computation. Thus, to guarantee this, mobile device 4 can only perform the computation on its data with a very small size.
VI. CONCLUSION
In this paper, we have presented the Stackelberg game model to analyze the transmission strategy and training data pricing strategy of the self-organized mobile device as well as the learning service subscription of the model owner in the cooperative federated learning system. We have focused on the interactions among the mobile devices and considered the impact of the interference cost on the mobile devicesâ€™ proï¬ts. Moreover, we have investigated the impact of the size of the training data on both the model ownerâ€™s utility and the mobile devicesâ€™s proï¬ts. Speciï¬cally, we have established a model describing the impact of the mobile devicesâ€™ transmission strategies on their transmission rates and relay node. The model also describes the impact of the model ownerâ€™s learning service subscription strategy on the model ownerâ€™s utility. We have studied the optimal strategy of the model owner by using best response and the equilibrium strategies of the mobile devices by using the exterior point method. Our future work will extend to the study in the long-run among the model owner and the mobile devices.
ACKNOWLEDGEMENT
This work was supported in part by A*STAR-NTU-SUTD Joint Research Grant Call on Artiï¬cial Intelligence for the Future of Manufacturing RGANS1906, WASP/NTU M4082187

(4080), Singapore MOE Tier 1 under Grant 2017-T1-002007 RG122/17, MOE Tier 2 under Grant MOE2014-T2-2-015 ARC4/15, Singapore NRF2015-NRF-ISF001-2277, and Singapore EMA Energy Resilience under Grant NRF2017EWTEP003-041.

REFERENCES

[1] S. Feng, W. Wang, D. Niyato, D. I. Kim and P. Wang, â€œCompetitive data

trading in wireless-powered internet of things (iot) crowdsensing systems

with blockchain,â€ arXiv preprint arXiv:1808.10217, 2018.

[2] D. W. Opderbeck, â€œCybersecurity, data breaches, and the economic loss

doctrine in the payment card industry,â€ Md. L. Rev., vol. 75, pp. 935,

2015.

[3] google,

â€œFederated learning: Collaborative machine learning

without centralized training data,â€ https://ai.googleblog.com/2017/

04/federated-learning-collaborative.html, Accessed April 6, 2017.

[4] TensorFlow,

â€œMachine learning and mobile: Deploy-

ing models on the edge,â€ https://blog.algorithmia.com/

machine-learning-and-mobile-deploying-models-on-the-edge/, Accessed

June 21, 2018.

[5] J. Konecny`, H. B. McMahan, D. Ramage and P. RichtaÂ´rik, â€œFederated

optimization: Distributed machine learning for on-device intelligence,â€

arXiv preprint arXiv:1610.02527, 2016.

[6] B. Gu, F. Hu and H. Liu, â€œModelling classiï¬cation performance for

large data sets,â€ in International Conference on Web-Age Information

Management. Springer, 2001, pp. 317â€“328.

[7] A. Gharaibeh, T. Reza, E. Santos-Neto, L. B. Costa, S. Sallinen and

M. Ripeanu, â€œEfï¬cient large-scale graph processing on hybrid cpu and

gpu systems,â€ arXiv preprint arXiv:1312.3018, 2013.

[8] M. J. Osborne et al., An introduction to game theory, vol. 3, Oxford

university press New York, 2004.

[9] X. Yang, â€œAn exterior point method for computing points that satisfy

second-order necessary conditions for a c1, 1 optimization problem,â€

Journal of Mathematical Analysis and Applications, vol. 187, no. 1, pp.

118â€“133, 1994.

820

