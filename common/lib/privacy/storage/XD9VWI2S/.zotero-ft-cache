2017 IEEE/CIC International Conference on Communications in China (ICCC)

A Privacy-preserving Interactive Messaging Scheme Based on Users Credibility over Online Social Networks
Shunan Zhang 1, Ying Cai âˆ—2, Hongke Xia 3
Department of Computer Science, Beijing Information Science & Technology University, Beijing, 100101, China 1291469736@qq.com 2ycai@bistu.edu.cn 3kk325@126.com

Abstractâ€” Due to the tremendous growth in user population over online social networks (OSNs), interactive messaging trafï¬c has experienced exponential increase, which consequently elevates the privacy leakage. Malicious users may utilize camouï¬‚age, phishing and other unconventional techniques to lure ordinary users to reveal their sensitive attributes in their interactive messages, when they least expect that the other sides are malicious. Therefore, it is very important to identify malicious users quickly and successfully when socializing over OSNs. In this paper, we propose a privacy-preserving interactive messaging scheme by relying on user credibility, which characterizes usersâ€™ reputation through usersâ€™ social behaviors, and use the item response theory in psychometrics to assess the risk levels of usersâ€™ interactive messages. We have conducted extensive studies by sending interactive messages with sensitive attributes and have observed that the success rate of identifying malicious users based on user credibility is signiï¬cantly higher and our scheme can effectively lower the risk of privacy leakage in our interactive messaging system.
Index Termsâ€” Online Social Networks, Interactive Messaging, User Credibility, Item Response Theory, Risk
I. INTRODUCTION
Online Social Networks (OSNs) have become an indispensable part of our daily lives. Users can get to know a large number of new friends through OSNs and obtain more information by exchanging messages. Unfortunately, such convenience comes without price. In the process of socializing, users often disclose their private information intentionally or unintentionally.
Due to national privacy policy restrictions, neither the social platform service provider nor the third party service facilitator has the right to disclose usersâ€™ interactive contents containing private information. These policies make it difï¬cult to measure privacy in interactive messages, so there is relatively little privacy protection schemes for interactive messages. Some schemes set usersâ€™ authority of interactive messaging only based on usersâ€™ attitude towards privacy concerns. Others attempt to protect usersâ€™ privacy by optimizing user privacy settings. However, the process of manually setting privacy
*Ying Cai is the corresponding author.

is very cumbersome, which will wear out usersâ€™ patience and they may just skip the stage of privacy settings. Some schemes suggest using early warning measures, warning users before they send sensitive messages to others in an untrusted network environment. Unfortunately, the actual effect of this early warning mechanism is not really effective because many users tend to ignore the warning and send sensitive messages out without scrutiny.
In this paper, by taking into account the characteristics of usersâ€™ interactive messages and the disadvantages of existing schemes, we propose a privacy protection scheme based on user credibility. Our scheme measures the user credibility based on usersâ€™ social behaviors over OSNs. Social behaviors can directly capture the inherent characteristics of a user. For example, we can learn a userâ€™s personality from the number of friends he/she often contacts with and the number of interactive messages exchanged. It can also capture the relationships indirectly among users. For instance, we can determine whether two users are friends through the contact frequency. Therefore, a userâ€™s credibility can be ï¬ne-tuned to determine whether a user is malicious. On the other hand, since the usersâ€™ interactive messages may contain his/her sensitive attributes, we also need to characterize the risk level for interactive messages. The captured risk level of a userâ€™s interactive messages can be used to control whether the user sends messages or not.
The rest of the paper is organized as follows. Section 2 presents the related work. In Section 3, we introduce the adversarial model, a userâ€™s credibility and messages risk assessment mechanism, and describe how to measure the credibility and the risk level. In Section 4, we conduct performance evaluation of our scheme and show its effectiveness in addressing privacy concerns in interactive messaging. Section 5 concludes the paper.
II. RELATED WORK
The deï¬nition of online social networks (OSNs) was ï¬rst formally proposed by Boyd et al.[1] in 2007. Since then, OSNs have received intensive attention. Wang et al.[2] modeled

978-1-5386-4502-4/17/$31.00 Â©2017 IEEE

2017 IEEE/CIC International Conference on Communications in China (ICCC)

social threats from social networking sites, third-party service providers, social network users, and attackers, and considered six security factors. This model can be used to effectively analyze the behaviors of attackers and capture privacy leaks in detail. In face of various privacy leaks, many research works have been carried out.
A. Privacy Score Mechanism
Privacy is a very difï¬cult to address as different users have different standard for their privacy. Privacy can be protected by using privacy setting according to privacy scores. Liu et al.[3] used the item response theory (IRT) to evaluate usersâ€™ privacy scores, which can be used to recommend privacy settings for users. However, the scheme relies on usersâ€™ attitude towards sensitive attributes, and hence it depends on a certain degree of subjectivity. Li et al.[4] proposed a trust-based privacy setup system to help users choose privacy preferences. Unfortunately, this setup process of privacy setting still contains usersâ€™ subjective preference. Srivastava et al.[5] used privacy entropy to measure the privacy degree of user identity messages. Vidyalakshmi et al.[6] designed a privacy score function based on the cubic Bezier curve according to usersâ€™ privacy preference to determine whether a user can join the circle of friends. Qian et al.[7] constructed a model of privacy reasoning based on attackersâ€™ knowledge. However, this model has not considered the correlation of prior knowledge and the characteristics of the corresponding probability distributions. Petkos et al.[8] summarized the privacy scores for privacy settings, including user-deï¬ned attribute sensitivity and developed mechanisms to set different levels according to the combination of attribute messages. This indeed provides a theoretical foundation for privacy score research. Otsuki et al.[9] proposed a method for measuring the priority of user attributes and investigated the sensitivity of message attributes, which could capture usersâ€™ privacy attitude objectively.
B. Trust or Reputation Based Privacy Protection
Privacy can also be protected based on user controlled message sharing according to either trust or reputation. Li et al.[10] used usersâ€™ trust degree and contact time intervals to measure user credibility, but the deï¬nition of trust is too coarse. Abbasi et al.[11] measured the credibility of messages sent by users based on the propagation of error messages and rumors. The measurement took into account the similarity of usersâ€™ behavior, but failed to specify how to quantify usersâ€™ behavior. Guo et al.[12] designed a user reputation system according to usersâ€™ behaviors, which veriï¬ed usersâ€™ property by the third party platform and voted for authenticated users based on reputation. Gambhir et al.[13] deï¬ned trust factors based on usersâ€™ behaviors and interactive messages to determine user credibility. Unfortunately, there is lacking sound theoretical foundation for the deï¬nition of usersâ€™ behaviors and the weight of interactive messages.
C. Other Privacy Protection Approaches
There are also other related works addressing privacy issues. Reynaert et al.[14] proposed a framework to improve privacy

protection, which was primarily based on the anonymity of social graphs and the security of messages ï¬‚ow in browsers. Palomar et al.[15] developed an access control protocol for message sharing, which could set permissions for data sharing by the data owner and co-managers together. Li et al.[16] designed a node perturbation algorithm based on k-anonymity, which could effectively prevent one hop or multi-hop friends from revealing anonymous messages. Ahmed et al.[17] proposed a method of adding virtual nodes to ensure k-anonymity, which could deal with recognition attack of a group of messages.
III. SYSTEM DESIGN
In this section, we present our scheme on the privacy protection for interactive messaging over OSNs and elaborate it from three aspects: attack model, user credibility and messages risk assessment mechanism.
A. Attack Model
Depending on interactive messages, attacks can be divided into two categories. First, we assuming that there are an attacker A and an ordinary user U in an OSN site. The friends of U, the family of U, and the colleagues of U are also registered with this OSN site. The attribute set of U is AT T RU (attr1, attr2, attr3, attr4, ...). Attacker A obtains some attributes of U previously by some means of attacks and registers with the OSN site as UA, which has a set of attributes AT T RUA (attr1, attr3, attr4, ...) that are highly similar to U. Due to different people identify U by different combination of attributes, so they may mistake A for U, and may leak their own privacy to A, as shown in Fig. 1. Then attacker A can obtain their relatives and friendsâ€™ privacy by the same way after getting their privacy.

Ä‚ÆšÆšÆŒÏ­à·¦Ä‚ÆšÆšÆŒÏ®à·¦Ä‚ÆšÆšÆŒÏ¯

Í¾Ä‚ÆšÆšÆŒÏ­Ä‚ÆšÆšÆŒÏ®Í• Ï® Ä‚ÆšÆšÆŒÏ¯Í•Ä‚ÆšÆšÆŒÏ°Í˜Í˜Í˜Í¿
h Æ‰ÆŒÄÆšÄÅ¶Äš h

ÄÅ½Å¯Å¯ÄÄ‚ÅÆµÄÆ

Ï­
Í˜Í˜Í˜

Ï¯

ÅÄšÄÅ¶ÆšÅÄ¨Ç‡
Í¾Ä‚ÆšÆšÆŒÏ­Ä‚ÆšÆšÆŒÏ¯Í•Ä‚ÆšÆšÆŒÏ°Í•Í˜Í˜Í˜Í¿
ÅÄšÄÅ¶ÆšÅÄ¨Ç‡

&Ï­
Í˜Í˜Í˜ &ÆŒÅÄÅ¶ÄšÆ

&Ä‚ÅµÅÅ¯Ç‡
WÏ®

&Ï®

ÅÄšÄÅ¶ÆšÅÄ¨Ç‡

WÏ­

Í˜Í˜Í˜

WÏ¯

Ä‚ÆšÆšÆŒÏ­á…Ä‚ÆšÆšÆŒÏ¯

Ä‚ÆšÆšÆŒÏ­á…Ä‚ÆšÆšÆŒÏ¯á…Ä‚ÆšÆšÆŒÏ°

Fig. 1. The ï¬rst type of attack Model

Second, suppose that there are an attacker A and an ordinary user set SETU (U1, U2, U3, ...). Attacker A uses the obtained fake attributes to register as UA. In order to obtain the private information from a larger number of OSNs users, UA sends friend requests to all users in SETU . For some users who like to make friends, the request will be granted under normal

2017 IEEE/CIC International Conference on Communications in China (ICCC)

circumstances. Once UAâ€™s requests are granted, UA will push messages with malicious links to users who become friends
of UA in SETU . As soon as a user clicks to a link, he/she may leak his/her privacy to UA. When UA reaches this goal, he could delete the existing friends and then continue the next
round of attacks.

B. User Credibility
In order to protect usersâ€™ privacy in interactive messaging systems, it is important to recommend users to manage their interactions with cautions in terms of whom they interact with and what they exchange. For user to user interactions, users need to add each other as their friends. Unfortunately, many users do not usually verify each other before granting their requests, which introduces a potential threat for privacy invasion.
The aforementioned situation displays the fact that many users have not paid enough attention to protect their privacy, which will potentially result in privacy leakage of many other users. To deal with this problem, we introduce the concept of user credibility, Cre, based on usersâ€™ social behaviors, as deï¬ned in Deï¬nition 1 below. By using this metric, we could improve the probability of recognizing malicious users and limit the social interactions with low-conï¬dence users.
Deï¬nition 1 (User Credibility): User Credibility, Cre, for a user is deï¬ned as the degree that the user is credible to all other users over the OSN considered. It is characterized by the userâ€™s social behaviors.
Before presenting our method to mathematically characterize the user credibility in detail, we need to deï¬ne the precise deï¬nition of a completed session between a user and another user as follows.
Deï¬nition 2 (Completed Session): A completed session between user A and user B is deï¬ned as the interactive session between A and B with at least a prescribed time period of silence, say, T , before and after the session, i.e., the time interval between the last message of this session and the ï¬rst message of the next session needs to be greater than T , where T depends on the speciï¬c OSN environment. In other words, a completed session between A and B is the session from the start of the interaction to the last message followed by a silence period of a prescribed time T .
Now we are ready to give our method to calculate user credibility. We assume that in the interaction process between user A and user B, the factors to be considered in the measurement of CreUâ†”U (A, B) can be expressed as < Prep(A, B), Pcon(A, B), Pses(A, B) >. Prep(A, B). Prep(A, B) denotes the message response rate of user B to user A, as shown in equation (1):

Prep(A, B)

=

Trep(B, A) Tsen(A, B)

(1)

where Trep(B, A) denotes the number of replies of B to A in all sessions which A sends the ï¬rst message, Tsen(A, B) denotes the times A ï¬rst sends messages to B in all sessions.

Pcon(A, B) denotes the ratio of effective days of interactions between A and B, as shown in equation (2):

Pcon(A, B)

=

Dcon(A, B) Dall(A, B)

(2)

where Dcon(A, B) denotes the effective days of interactions between A and B, Dall(A, B) denotes the total number of days when A and B are friends so far. One effective day of interactions is deï¬ned as both sides have at least one reply to each other in one day. In other words, within a day, if A sends a message to B, B should reply to A, and then A should continue reply to B. Pses(A, B) is the effective session ratio between A and B as deï¬ned in equation(3):

Pses(A, B)

=

Tses(A, B) Tall(A, B)

(3)

where Tses(A, B) denotes the number of completed sessions between A and B. Tall(A, B) denotes the number of sessions between A and B (including the sessions that one party sends a messages, but does not receive reply).
Due to the frequency of interactions are different between A and each of his/her friends, we assume that the friends with Prep(A, B), Pcon(A, B) and Pses(A, B) equal to 0 are negative friends, while the rest of the friends were active friends. We only calculate Aâ€™s credibility through positive friends. Meanwhile, user A needs to maintain two lists of friends. One is the list of current friends, which contains the existing friends of user A so far (not including deleted friends) and the number is denoted as l. The other one is the list of past friends, which contains all friends who have been added by user A since A creates the account (including deleted friends) and the number is denoted as m (lâˆˆm). The number of active friends of user A is n, then the Aâ€™s credibility Cre(A) can be calculated as in equation (4):

C re(A)

=

(1 n

n i=0

aÂ·Prep(A, B)

+

bÂ·Pcon(A, B)

(4)

+cÂ·Pses(A,

B))Â·(

n l

+

l m

)Â·

1 2

where n/l is the proportion of active friends. When n is larger, it may indicate that the popularity of the current user in OSNs is higher. l/m reï¬‚ects the purpose of the current userâ€™s social activities. The smaller the ratio is, indicating that the user has deleted more friends, the higher likelihood that it is a malicious user. a, b, c are the weights corresponding to each factor, respectively, summing up to 1.

C. Messages Risk Assessment Mechanism
Since different users have different levels of privacy awareness, the number of sensitive attributes included in the interactive messages will be different. Information for users with the same sensitive attributes may be comfortably shared with friends in reality, but it may not be shared with strangers due to privacy concerns. Therefore, in this section, we will analyze

2017 IEEE/CIC International Conference on Communications in China (ICCC)

the messages risk rating mechanism based on userâ€™s credibility. Here we ï¬rst deï¬ne the sensitive attribute parameter set (SAPS) between users, as deï¬ned in Deï¬nition 3.
Deï¬nition 3 (SAPS): In all messages that a user sends to another one, they all have several sensitive attributes. The parameters of sensitive attribute i can be denoted as (Î±i, Î²i), where Î±i denotes the attribute discrimination, and Î²i denotes the attribute sensitivity. A set consisting of these sensitive attribute parameters is called SAPS.
Each user maintains an SAPS corresponding to each other user, and the determination of the sensitive attribute parameters will be discussed in the subsequent subsections.
We will rely on the method for evaluating a userâ€™s privacy score developed by LIU et al.[3], and make use of the project response theory to evaluate the message risk level.
1) Project Response Theory (IRT): Project Response Theory is a theory on psychological measurements. It is used for the project screening and test preparation. In this paper, we use an IRT model with two parameters. In this model, the characteristics of a question qi to be measured is represented by a pair of parameters Î¾i = (Î±i, Î²i), where Î±i denotes the distinction degree of question i, and Î²i denotes the difï¬culty of question i. The characteristics of each examinee j are represented by a parameter Î¸j, where Î¸j denotes the ability of the examinee j. The basic random variable in the IRT model is to capture the quality of the examineeâ€™s answer to the question qi. In case that the result is only â€correctâ€ or â€wrongâ€, the probability of the examineeâ€™s answer to question qi is given in equation (5):

Pij

=

1 1 + eâˆ’Î±i(Î¸j âˆ’Î²i)

(5)

This model requires three basic assumptions, namely: (1) independence between questions.(2) independence between examinees; and (3) independence between question and examinee.
2) Risk Levels of Messages: Our scheme uses the IRT model to determine the risk levels of the messages sent by users. First of all, We need to map the IRT model to suit our problem. Thus, as shown in Fig. 2, in our IRT model, we treat message receiver B as examinee j, the sensitive attribute Î¾i in the SAPS is regarded as the question qi, and and the credibility of the message receiver is equivalent to the examineeâ€™s ability Î¸i. The lower the credibility, the less sensitive the attributes. Î±i and Î²i correspond to the parameters of Î¸i in SAPS, and Pij denotes the success rate of the message receiverâ€™s acquisition of the sensitive attribute i.
In order to determine the risk level of messages sent by users, it is necessary to determine the sensitivity of all attributes and the success rate of the message receiverâ€™s acquisition of each sensitive attribute. Therefore, we need to collect all sensitive attribute parameters Î¾i = (Î±i, Î²i) in all messages sent by one user.
Our scheme also uses the maximum likelihood estimation method to estimate the sensitive attribute parameters Î¾i = (Î±i, Î²i), as shown in algorithm 1. Therefore, we need to

 ÆÄÅ¶Äš

DÄÆÆÄ‚ÅÄ

Ä‚ÆšÆšÆŒÏ­Í•Ä‚ÆšÆšÆŒÏ®Í•Ä‚ÆšÆšÆŒÏ¯Í• ÄŠÍ•Ä‚ÆšÆšÆŒÅ

ÆÄÅ¶Äš 

Æ‹ÆµÄÆÆšÅÅ½Å¶Æ‹Å
ÄšÅÆÄÆŒÅÅµÅÅ¶Ä‚ÆšÅÅ½Å¶ Æ‰Å½ÇÄÆŒÉ²Å
ÄšÅÄ¨Ä¨ÅÄÆµÅ¯ÆšÇ‡É´Å ÄÇ†Ä‚ÅµÅÅ¶ÄÄÇ­Æ
Ä‚ÄÅÅ¯ÅÆšÇ‡É½Å

ÄÇ†Ä‚ÅµÅÅ¶ÄÄÅ©
Ä‚ÆŒÆŒÆšÅÄÆµÆšÄÄ‚ÆšÆšÆŒÅ
ÄšÅÆÄÆŒÅÅµÅÅ¶Ä‚ÆšÅÅ½Å¶ Æ‰Å½ÇÄÆŒÉ²Å
ÆÄÅ¶ÆÅÆšÅÇ€ÅÆšÇ‡É´Å ÆŒÄÄÅÄÇ€ÄÆŒÇ­Æ ÄÆŒÄÄšÅÄÅÅ¯ÅÆšÇ‡É½Å

Fig. 2. Mapping relations of our scheme and IRT model

Algorithm 1 Estimation of Î¾i = (Î±i, Î²i) for all sensitive

attributes

Input:

Messages msg, recieverâ€™s credibility Î¸ = (Î¸1, ..., Î¸N ) and

the number F of recieverâ€™s credibility groups.

Output:

Î± = (Î±1, ..., Î±N ) and Î² = (Î²1, ..., Î²N ) 1: {Gg, Î¸g}Fg=1â†âˆ’P atitionreciever(Î¸, F )
2: for g=1 to F do

3:

pg â†âˆ’|Gg |

4: for i=1 to n do

5:

wig = |{j|jâˆˆGg Inf oset(i, j) = 1}|

6: for i=1 to n do

7:

(Î±i, Î²i)â†âˆ’N R Estimation(msg, {Pg, wig, Î¸g}Kg=1)

ï¬nd the maximum likelihood estimate of Î¾i to maximize the likelihood function(6),

N

PiIjnf o(i,j)(1 âˆ’ Pij )1âˆ’Inf o(i,j)

(6)

j=1

where Inf o(i, j) indicates whether the user j wants to get
the attribute i of the messages. The likelihood function as-
sumes that the credibility levels of all users are different. However, in reality, OSN users {1, ..., N } can be divided into F non-overlapping groups {G1, ..., GF }, where Fg=1Gg = {1, ..., N }, users of each group have same credibility. Let Î¸g represent the credibility of user group Gg, and pg denotes the number of users in group Gg. For each sensitive attribute i, let wig represent the number of people who have succeeded in obtaining the other userâ€™s attribute i in the user group Gg, that is, wig = |{j|jâˆˆGg Inf oset(i, j) = 1}|. Therefore, the above likelihood function can be further expressed as in (7).

N

[Pi(Î¸g)]wig [1 âˆ’ Pi(Î¸g)]pgâˆ’wig

(7)

g=1

2017 IEEE/CIC International Conference on Communications in China (ICCC)

and the corresponding log-likelihood function is shown in (8).
K
L = (wiglogPi(Î¸g) + (pg âˆ’ wig)log(1 âˆ’ Pi(Î¸g))) (8)
g=1
We use the Newton-Raphson algorithm in maximizing the log-likelihood function, and the algorithm gives the estimated value Î¾i = (Î±i, Î²i) through calculating the ï¬rst order derivative and the second order derivative with respect to Î±i and Î²i iteratively, and then, we can obtain the Î±i and Î²i.
Finally, We take user credibility Î¸i and the sensitive attribute parameters Î¾i into formula(5), and use the equation (9) to calculate the risk level PR(j) of SAPS sent by user.

P R(j)

=

n i=1

Î²iÃ—

1 Pij

(9)

Before the initial contact session between user A and user B, the SAPS of both sides are empty. When user A sends each message to user B, the risk level of each message is determined by using the above method. As long as user A sends a message, the system records sensitive attribute parameters contained in this message into the SAPS. With the progress of the session, the SAPS of user A will contain multiple sensitive attribute parameters gradually. When the risk level of the messages sent by user A is too high, the system will issue a warning to user A, and user A can choose whether continue to send more message to user B based on the nature of the warning.

IV. EXPERIMENT STUDY
Since user credibility has signiï¬cant impact on the assessment of messages risk level, we will use a Facebooklike Social Network data set to evaluate user credibility in this study. Here, we simulated a number of malicious users according to the behavioral characteristics of malicious users in OSNs, and added them to the data set. More speciï¬clly, the data set contains speciï¬c timestamps of interactive messages of 1100 users (including 100 malicious users). During the analysis, we set T to be 12 hours. Our goal is to identify as many malicious users as possible, and reduce the error recognition rate.

A. Distribution of user credibility
We can get the distribution of user credibility by calculating, as can be seen in the Fig. 3.
The number of ordinary users whose credibility in 0.1âˆ¼0.2 and 0.2âˆ¼0.3, respectively, are small, and the number of ordinary users whose credibility in 0âˆ¼0.1, 0.3âˆ¼0.4 and 0.4âˆ¼0.5 respectively, are large, and the number of ordinary users whose credibility in 0.7âˆ¼0.9 is the smallest. Fortunately, most of malicious user credibility less than 0.2, and a small part of them between 0.2âˆ¼0.4, so they are divided into low-credibility users.
After the careful analysis, we conclude that the user whose credibility higher than 0.5 have a lot of active friends, so they

Ï¯Ï±Ï¬

dÅšÄÅ¶ÆµÅµÄÄÆŒÅ½Ä¨Å½ÆŒÄšÅÅ¶Ä‚ÆŒÇ‡ÆµÆÄÆŒÆ

Ï¯Ï¬Ï¬

Ï®Ï±Ï¬

d ÅšÄÅ¶ÆµÅµ ÄÄÆŒ Å½Ä¨Åµ Ä‚Å¯ÅÄ ÅÅ½ÆµÆÆµÆ ÄÆŒ Æ

Ï®Ï¬Ï¬

Ï­Ï±Ï¬

Ï­Ï¬Ï¬

Ï±Ï¬

Ï¬ Ï¬Î•Ï¬Í˜Ï­ Ï¬Í˜Ï­Î•Ï¬Í˜Ï® Ï¬Í˜Ï®Î•Ï¬Í˜Ï¯ Ï¬Í˜Ï¯Î•Ï¬Í˜Ï° Ï¬Í˜Ï°Î•Ï¬Í˜Ï± Ï¬Í˜Ï±Î•Ï¬Í˜Ï² Ï¬Í˜Ï²Î•Ï¬Í˜Ï³ Ï¬Í˜Ï³Î•Ï¬Í˜Ï´ Ï¬Í˜Ï´Î•Ï¬Í˜Ïµ
hÆÄÆŒÆÎ– ÆŒÄÄšÅÄÅÅ¯ÅÆšÇ‡Í¾Ğ¹Í¿

Fig. 3. Distribution of ordinary user credibility

TABLE I DISTRIBUTION OF ORDINARY USERSâ€™ FRIENDS AND CREDIBILITY

User(No.)
569 36 189 204 144 32 1253 1339 372 1285

Positive user (quantity) 2 6 3 8 19 52 11 16 67 21

Negative user (quantity) 14 75 25 58 35 86 20 15 37 11

Userâ€™s Credibility(%)
0.074 0.071 0.161 0.179 0.267 0.372 0.364 0.435 0.460 0.510

are less likely to be malicious users. Users whose credibility in 0.2âˆ¼0.5 also have many friends, but the number of active friends less than high-credibility users. Users whose credibility in 0âˆ¼0.2 are belong to low-credibility users. Although most of them have a lot of friends, but both sides do not have information interactions, and it often happens that a user sends a message and the other user does not respond.
Next, we discuss the initialization of user credibility for newly registered users. When the credibility is initialized to 0, it is difï¬cult for newly registered users to get socially active at the very start, and so we use the average credibility of all active users in OSNs to initialize user credibility for newly registered users.
B. Ordinary User Credibility
We take No.103 ordinary user as an example, because he has a large number of friends relative to other ordinary users. He has 216 friends in total, including 53 active friends and 163 negative friends, as shown in Fig. 4(a). Although he has a lot of friends, his credibility is only 0.28. At the same time, we also analyze 10 different ordinary users randomly selected in different credibility intervals, as shown in Table I. The results show that user credibility is related to the proportion of positive and negative friends. With the increase of the proportion of positive friends, the user credibility is also improved.
C. Malicious User Credibility
We take No.2064 malicious user as an example in this analysis, because he has a great number of friends relative to

2017 IEEE/CIC International Conference on Communications in China (ICCC)

Æ‰Å½ÆÅÆš ÅÇ€Ä Ä¨ÆŒÅÄÅ¶ÄšÆ

Å¶ÄÅÄ‚Æš ÅÇ€ÄÄ¨ ÆŒÅÄÅ¶ÄšÆ Ï¯Ğ¹

Ï®Ï±Ğ¹

Ï³Ï±Ğ¹ ÏµÏ³Ğ¹

Í¾Ä‚Í¿EÅ½Í˜Ï­Ï¬Ï¯Å½ÆŒÄšÅÅ¶Ä‚ÆŒÇ‡ÆµÆÄÆŒ

Í¾ÄÍ¿EÅ½Í˜Ï®Ï¬Ï²Ï°ÅµÄ‚Å¯ÅÄÅÅ½ÆµÆÆµÆÄÆŒ

Fig. 4. The propotion of positive friends and negative friends

TABLE II DISTRIBUTION OF MALICIOUS USERSâ€™ FRIENDS AND CREDIBILITY

User(No.)
2016 2038 2014 2098 2030 2048 2069 2022 2073 2089

Positive user (quantity) 5 6 15 16 12 5 7 9 18 13

Negative user (quantity) 210 258 199 132 41 183 59 178 35 28

Userâ€™s Credibility(%)
0.014 0.025 0.063 0.078 0.088 0.093 0.102 0.135 0.219 0.323

other malicious users. He has 415 friends in total, including 12 active friends and 403 negative friends, as shown in Fig. 4b. We also randomly select 10 other malicious users for our analysis, as shown in table II. The results show that the credibility of malicious users is generally low.
With the improvement of privacy awareness, most ordinary users will disregard messages which are sent by such malicious users. Even if there are a small part of users interact with them, the frequency of interaction is low. This will lead to such malicious users have fewer positive friends and more negative friends.
V. CONCLUSION
In this paper, we propose an interactive message privacy protection scheme based on user credibility in OSNs. We measure user credibility by social behaviors, and then apply the IRT model to assess the risk level of messages. Users can not only choose whether to add friends by user credibility, but also choose whether to send messages with sensitive attributes according to other user credibility. Our scheme provides users with useful recommendation for message risk level before users send out messages that contain sensitive attributes. Through extensive analysis and experimental veriï¬cation, we demonstrate that the most of malicious users are rated as low credibility users. Therefore, our scheme can effectively reduce the risk of privacy leakage in future interactive messaging systems.

ACKNOWLEDGMENT
The authors would like to thank Prof. Yuguang Fang for
providing many useful suggestions for our scheme.
The work is supported by the National Natural Science
Foundation of China under Grant No.61672106 and the Gen-
eral Program of Science and Technology Development Project
of Beijing Municipal Education Commission under Grant
No.KM201611232013.
REFERENCES
[1] N. B. Ellison et al., â€œSocial network sites: Deï¬nition, history, and scholarship,â€ Journal of Computer-Mediated Communication, vol. 13, no. 1, pp. 210â€“230, 2007.
[2] Y. Wang and R. K. Nepali, â€œPrivacy threat modeling framework for online social networks,â€ in Collaboration Technologies and Systems (CTS), 2015 International Conference on. IEEE, 2015, pp. 358â€“363.
[3] K. Liu and E. Terzi, â€œA framework for computing the privacy scores of users in online social networks,â€ ACM Transactions on Knowledge Discovery from Data (TKDD), vol. 5, no. 1, p. 6, 2010.
[4] L. Li, T. Sun, and T. Li, â€œPersonal social screenâ€“a dynamic privacy assignment system for social sharing in complex social object networks,â€ in IEEE Third International Conference on Privacy, Security, Risk and Trust, 2011, pp. 1403â€“1408.
[5] A. Srivastava and G. Geethakumari, â€œMeasuring privacy leaks in online social networks,â€ in Advances in Computing, Communications and Informatics (ICACCI), 2013 International Conference on. IEEE, 2013, pp. 2095â€“2100.
[6] B. S. Vidyalakshmi, R. K. Wong, and C. H. Chi, â€œPrivacy scoring of social network users as a service,â€ in IEEE International Conference on Services Computing, 2015, pp. 218â€“225.
[7] J. Qian, X. Y. Li, C. Zhang, and L. Chen, â€œDe-anonymizing social networks and inferring private attributes using knowledge graphs,â€ in IEEE INFOCOM 2016 - the IEEE International Conference on Computer Communications, 2016.
[8] G. Petkos, S. Papadopoulos, and Y. Kompatsiaris, â€œPscore: A framework for enhancing privacy awareness in online social networks,â€ in Availability, Reliability and Security (ARES), 2015 10th International Conference on. IEEE, 2015, pp. 592â€“600.
[9] M. Otsuki and N. Sonehara, â€œEstimating the value of personal information with sns utility,â€ in Eighth International Conference on Availability, Reliability and Security, 2013, pp. 512â€“516.
[10] M. Li and A. Bonti, â€œT-osn: A trust evaluation model in online social networks,â€ in Iï¬p International Conference on Embedded and Ubiquitous Computing, 2011, pp. 469â€“473.
[11] H. Liu and M. Abbasi, â€œMeasuring user credibility in social media,â€ Social Computing, Behavioral-Cultural Modeling and Prediction, pp. 441â€“448.
[12] L. Guo, Y. Fang, and L. Wei, â€œFine-grained privacy-preserving reputation system for online social networks,â€ in Communications in China (ICCC), 2013 IEEE/CIC International Conference on. IEEE, 2013, pp. 230â€“235.
[13] M. Gambhir, M. Doja, et al., â€œAction-based trust computation algorithm for online social network,â€ in Advanced Computing & Communication Technologies (ACCT), 2014 Fourth International Conference on. IEEE, 2014, pp. 451â€“458.
[14] T. Reynaert, W. De Groef, D. Devriese, L. Desmet, and F. Piessens, â€œPesap: A privacy enhanced social application platform,â€ in Ase/ieee International Conference on Social Computing and 2012 Ase/ieee International Conference on Privacy, Security, Risk and Trust, 2012, pp. 827â€“833.
[15] E. Palomar, L. GonzaÂ´lez-Manzano, A. Alcaide, and AÂ´ . GalaÂ´n, â€œImplementing a privacy-enhanced attribute-based credential system for online social networks with co-ownership management,â€ IET Information Security, vol. 10, no. 2, pp. 60â€“68, 2016.
[16] C. Li, B. Palanisamy, and J. Joshi, â€œSocialmix: Supporting privacy-aware trusted social networking services,â€ in Web Services (ICWS), 2016 IEEE International Conference on. IEEE, 2016, pp. 115â€“122.
[17] K. W. Ahmed, I. J. Mouri, R. Zaman, and N. Yeasmin, â€œA privacy preserving personalized group recommendation framework,â€ in Advanced Computing (IACC), 2016 IEEE 6th International Conference on. IEEE, 2016, pp. 594â€“598.

